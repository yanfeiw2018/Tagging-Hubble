{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "import csv\n",
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/Users/yanfeiwang/Downloads/hst_bibcode_prog_associations.json', 'r') as f:\n",
    "    assoc = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/Users/yanfeiwang/Downloads/hst_progs.json', 'r') as f:\n",
    "    progs = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(assoc),type(assoc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assoc.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(assoc['bibcodes'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(assoc['bibcodes'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_assoc = pd.DataFrame(assoc['bibcodes'])\n",
    "df_assoc.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(progs['programs'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "progs['programs'][:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_progs = pd.DataFrame(progs['programs'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "6402 in df_progs['program']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "typeof2 = [];\n",
    "for i in range(len(df_assoc)):\n",
    "    typeof2.append(type(df_assoc.loc[0, 'programs']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_progs.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_progs.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(np.unique(df_assoc['bibcode']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_progs_trim = df_progs[['program','title']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_prog = {k: v for k, v in zip(df_progs['program'], df_progs['title'])}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_progs_trim.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df_progs_trim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_progs.loc[lambda df_progs: df_progs['program']==6402]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df_assoc['bibcode'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_assoc['flag'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_progs_trim.loc[df_progs['program']==13450]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_assoc.loc[3,'programs']+df_assoc.loc[4,'programs']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "key_v1 = pd.read_csv('/Users/yanfeiwang/Downloads/df_key_0629.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "key_v1 = key_v1[['bibcode','key_0629']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = sqlite3.connect('hubble.sqlite')\n",
    "cur = conn.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cur.execute('''DROP TABLE IF EXISTS publications''') \n",
    "cur.execute('''\n",
    "            CREATE TABLE publications(\n",
    "                id INTEGER NOT NULL PRIMARY KEY AUTOINCREMENT UNIQUE,\n",
    "                bibcode TEXT,\n",
    "                keywords TEXT,\n",
    "                FOREIGN KEY(bibcode) REFERENCES datasets(bibcode))\n",
    "                ''')\n",
    "conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cur.execute('''DROP TABLE IF EXISTS progs''') \n",
    "cur.execute('''\n",
    "            CREATE TABLE progs(\n",
    "                programs TEXT,\n",
    "                titles TEXT,\n",
    "                PRIMARY KEY(programs))\n",
    "                ''')\n",
    "conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cur.execute('''DROP TABLE IF EXISTS datasets''') \n",
    "cur.execute('''\n",
    "           CREATE TABLE datasets(\n",
    "                bibcode TEXT,\n",
    "                programs TEXT,\n",
    "                PRIMARY KEY(bibcode))\n",
    "                ''')\n",
    "\n",
    "conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in key_v1.iterrows():\n",
    "    try:\n",
    "        cur.execute('''\n",
    "                INSERT INTO publications(\n",
    "                bibcode,\n",
    "                keywords\n",
    "                ) VALUES (?,?)''',(row[0],row[1])\n",
    "               )\n",
    "    except sqlite3.Error as e:\n",
    "        print(e)\n",
    "conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in df_assoc.iterrows():\n",
    "    try:\n",
    "        cur.execute('''\n",
    "                INSERT INTO datasets(\n",
    "                bibcode,\n",
    "                programs\n",
    "                ) VALUES (?,?)''',(row[0], str(row[2]))\n",
    "               )\n",
    "    except sqlite3.Error as e:\n",
    "        print (e)\n",
    "conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in df_progs_trim.iterrows():\n",
    "    try:\n",
    "        cur.execute('''\n",
    "                INSERT INTO progs(\n",
    "                programs,\n",
    "                titles\n",
    "                ) VALUES (?,?)''',(row[0], row[1])\n",
    "               )\n",
    "    except sqlite3.Error as e:\n",
    "        print (e)\n",
    "conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cur.execute('''DROP TABLE IF EXISTS dataset_key''') \n",
    "cur.execute('''CREATE TABLE dataset_key AS\n",
    "                SELECT publications.bibcode, publications.keywords, datasets.programs\n",
    "                FROM publications JOIN datasets ON publications.bibcode = datasets.bibcode \n",
    "                ORDER BY publications.bibcode\n",
    "            ''')\n",
    "\n",
    "conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trial = pd.read_sql_query(\"SELECT * FROM publications\", conn)\n",
    "trial.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trial2 = pd.read_sql_query(\"SELECT * FROM datasets\", conn)\n",
    "len(trial2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trial3 = pd.read_sql_query(\"SELECT * FROM progs\", conn)\n",
    "len(trial3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_join = pd.read_sql_query(\"SELECT * FROM dataset_key\", conn)\n",
    "len(df_join)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_join[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "program_id = [];\n",
    "for i in range(len(df_join)):\n",
    "    program_id = program_id + ast.literal_eval(df_join['programs'][i])\n",
    "# converting the programs column to list of program IDs, and concatenate all the lists \n",
    "len(program_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_set = set(program_id)\n",
    "len(id_set) ### the total number of unique unique IDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert string to list for 'programs' column\n",
    "pro_list = [];\n",
    "for _ in range(len(df_join)):\n",
    "    pro_list.append(ast.literal_eval(df_join['programs'][_]))   \n",
    "len(pro_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert string to list for 'keywords' column\n",
    "key_list = [];\n",
    "for _ in range(len(df_join)):\n",
    "    key_list.append(ast.literal_eval(df_join['keywords'][_]))   \n",
    "len(key_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loop through the list of program list, in order to aggregate keywords from publications to \n",
    "# datasets, and store the citation of datasets in a different dictionary\n",
    "id_key_dict = {}\n",
    "id_count_dict = {}\n",
    "for pro_id in id_set:\n",
    "    id_key_dict[pro_id] = [];\n",
    "    id_count_dict[pro_id] = 0\n",
    "    for i in range(len(pro_list)):\n",
    "        if pro_id in pro_list[i]:\n",
    "            id_key_dict[pro_id] = id_key_dict[pro_id] + key_list[i];\n",
    "            id_count_dict[pro_id] = id_count_dict[pro_id] + 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_list = list(id_set)\n",
    "%store id_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keyy = np.unique(id_key_dict['2887'], return_counts = True)[0].tolist()\n",
    "repp = np.unique(id_key_dict['2887'], return_counts = True)[1].tolist()\n",
    "dict_trial = {k: v for k, v in zip(keyy, repp)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for iddd in dict_trial.keys():\n",
    "    dict_trial[iddd] = (dict_trial[iddd]/id_count_dict['2887'], id_count_dict['2887'])\n",
    "# dict_trial.value is tuple type, whose first element is frequency, second element is absolute count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_list.index('9122')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%store -r cal_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#final_list is a list of dictionary, each dictionary is for one dataset, the dictionary is keywords: (freq, count)\n",
    "final_list_1 = [];\n",
    "for _id in id_key_dict:\n",
    "    keyy = np.unique(id_key_dict[_id], return_counts = True)[0].tolist()\n",
    "    repp = np.unique(id_key_dict[_id], return_counts = True)[1].tolist()\n",
    "    dict_trial = {k: v for k, v in zip(keyy, repp)}\n",
    "    mean_cit = np.mean(repp)\n",
    "    for iddd in dict_trial.keys():\n",
    "        citation = dict_trial[iddd]\n",
    "        if iddd in cal_list:\n",
    "            dict_trial[iddd] = (0.001*dict_trial[iddd]/id_count_dict[_id], id_count_dict[_id])\n",
    "        elif citation > mean_cit:\n",
    "            dict_trial[iddd] = ((1+(citation-mean_cit)/(np.max(repp)-np.min(repp)))*dict_trial[iddd]/id_count_dict[_id], id_count_dict[_id])\n",
    "        else:\n",
    "            dict_trial[iddd] = (dict_trial[iddd]/id_count_dict[_id], id_count_dict[_id])\n",
    "    final_list_1.append(dict_trial)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(final_list_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v1_df = pd.DataFrame(final_list_1)\n",
    "# Takes a couple minutes to run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v1_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#all keywords\n",
    "listofkey = v1_df.columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v1_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Examine the keywords that are too popular to be actual keywords (if a word appears in 80 percent of the datasets)\n",
    "inte_columns = []\n",
    "for i in range(len(listofkey)):\n",
    "    if v1_df[listofkey[i]].isna().sum() <1288:\n",
    "        inte_columns.append(listofkey[i])\n",
    "        print(listofkey[i], v1_df[listofkey[i]].isna().sum())\n",
    "len(inte_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Examine the keywords that are rare\n",
    "inte_columns2 = []\n",
    "for i in range(len(listofkey)):\n",
    "    if v1_df[listofkey[i]].isna().sum() < 6421:\n",
    "        inte_columns2.append(listofkey[i])\n",
    "        print(listofkey[i], v1_df.shape[0]-v1_df[listofkey[i]].isna().sum())\n",
    "len(inte_columns2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this block is to shrink dataframe size, so it can run on unix miro on aws\n",
    "# if the website server has more memory, no need to run this cell\n",
    "kept_columns = []\n",
    "for i in range(len(listofkey)):\n",
    "    if v1_df[listofkey[i]].isna().sum() < 6356 and v1_df[listofkey[i]].isna().sum() >3219:\n",
    "        kept_columns.append(listofkey[i])\n",
    "len(kept_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'supernovae' in kept_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'gravitational lensing' in kept_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'galaxy evolution' in kept_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v2_df = v1_df[kept_columns]\n",
    "v2_df['ds_id'] = list(id_key_dict.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prog_titles = [];\n",
    "for _ in list(id_key_dict.keys()):\n",
    "    try:\n",
    "        prog_titles.append(dict_prog[int(_)])\n",
    "    except:\n",
    "        prog_titles.append('title not available')\n",
    "len(prog_titles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v2_df['title'] = prog_titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cal_index = v2_df.index[v2_df.ds_id.isin(cal_list)].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this block is to shrink dataframe size, so it can run on unix miro on aws\n",
    "v2_df = v2_df.drop(cal_index, axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v2_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v2_df.to_csv('/Users/yanfeiwang/Downloads/df_v2.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
